# Basics of Rate Limiting and Caching

## Introduction

API Gateways play a crucial role in managing traffic and improving performance for backend services. Two fundamental features provided by most API Gateways are **rate limiting** and **caching**. This document explains their basics, benefits, and common implementation strategies.

---

## 1. Rate Limiting

### What is Rate Limiting?

Rate limiting is a technique used to control the number of requests a client can make to an API within a specified time window. It helps protect backend services from being overwhelmed by too many requests, whether intentional (abuse) or accidental (bugs).

### Why Use Rate Limiting?

- **Prevents abuse and DDoS attacks**
- **Ensures fair usage among clients**
- **Protects backend resources**
- **Improves overall system stability**

### Common Rate Limiting Strategies

- **Fixed Window**: Limits requests per fixed time window (e.g., 100 requests per minute).
- **Sliding Window**: Similar to fixed window but calculates limits over a rolling time period.
- **Token Bucket**: Allows bursts of traffic up to a certain limit, then refills tokens at a steady rate.
- **Leaky Bucket**: Processes requests at a constant rate, queuing excess requests.

### Example

```yaml
# Example: Limit each client to 60 requests per minute
rate-limiting:
    enabled: true
    requests-per-minute: 60
```

---

## 2. Caching

### What is Caching?

Caching stores frequently accessed data temporarily so that future requests for the same data can be served faster, reducing the need to fetch or compute the data repeatedly.

### Why Use Caching?

- **Reduces latency for end-users**
- **Decreases load on backend services**
- **Improves scalability and performance**
- **Saves bandwidth and resources**

### Types of Caching

- **In-Memory Cache**: Fastest, stores data in RAM (e.g., Redis, Memcached).
- **Distributed Cache**: Shared across multiple servers for scalability.
- **Local Cache**: Stored on the API Gateway instance itself.

### Caching Strategies

- **Time-to-Live (TTL)**: Data is cached for a specific duration.
- **Cache Invalidation**: Mechanisms to clear or update stale data.
- **Cache Key Design**: Determines how cached data is identified and retrieved.

Example

```yaml
# Example: Cache GET responses for 5 minutes
caching:
    enabled: true
    methods: [GET]
    ttl: 300  # seconds
```

---

## Conclusion

Rate limiting and caching are essential features for any robust API Gateway. They help ensure reliability, security, and high performance for backend services. Understanding and configuring these features appropriately is key to building scalable and resilient APIs.
